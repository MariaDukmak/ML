{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris dataset testen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import sys, time, random, pandas as pd\n",
    "sys.path.append(\"/Users/marya/OneDrive/Bureaublad/ML2\")\n",
    "from neuron_bp import Neuron \n",
    "from neuron_layer_bp import Neuron_layer\n",
    "from neuron_network_bp import Neuron_network\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1756450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_number(n=1):\n",
    "    return [random.random() for _ in range((n))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data opsplitsen en reshapen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris data inladen\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aagezien mijn neuron netwerk input en traget van de type list nodig heeft, gaan we alles omzetten naar lijsten en geen nupmy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target = pd.get_dummies(iris.target)\n",
    "targets = [list(iris.target.iloc[i].values) for i in range(len(iris.data))]\n",
    "data = [list(iris.data[i]) for i in range(len(iris.data))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data using sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocessing.normalize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We spiten nu data in train en test set. Hiervoor maak ik gebruik van een bestande libray van sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size=0.43, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aanmaken van het netwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = Neuron(weights=[0.0, 0.1,0.0, 0.1], bias=0)\n",
    "n2 = Neuron(weights=[0.2, 0.3, 0.0, 0.1], bias=0)\n",
    "n3 = Neuron(weights=[0.4, 0.5, 0.0, 0.1], bias=0)\n",
    "layer1 = Neuron_layer([n1, n2, n3])\n",
    "\n",
    "n4 = Neuron(weights=[0.6, 0.7, 0.8], bias=0)\n",
    "n5 = Neuron(weights=[0.9, 1.0, 1.1], bias=0)\n",
    "n6 = Neuron(weights=[0.9, 1.0, 1.1], bias=0)\n",
    "\n",
    "layer2 = Neuron_layer([n4, n5, n6])\n",
    "\n",
    "netwerk = Neuron_network(layers=[layer1, layer2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train het netwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss 0.021243799660511174\n",
      "epoches 1000\n",
      "Het trainien heeft 7.884178161621094 seconden geduurt\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "netwerk.train(X_train, y_train, learning_rate = 0.1, epoches= 1000, max_time= 100)\n",
    "print(f\"Het trainien heeft {time.time()-start_time} seconden geduurt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bereken de accuracy score van het netwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(data):\n",
    "    antw= []\n",
    "    for i in data:\n",
    "        antw.append(netwerk.feed_forward(i))\n",
    "    antw = [[round(i) for i in nested] for nested in antw]\n",
    "    \n",
    "    return antw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(target, predict):\n",
    "    true = 0 \n",
    "    for i in range(len(target)):\n",
    "        if predict[i] == target[i]: true +=1 \n",
    "        else: print(f\" Het is {predict[i]}, maar je predict{target[i]}\")\n",
    "    return true/len(target) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Het is [0.0, 0.0, 1.0], maar je predict[0, 1, 0]\n",
      " Het is [0.0, 0.0, 1.0], maar je predict[0, 1, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "97.6470588235294"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, score(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Het is [0.0, 0.0, 1.0], maar je predict[0, 1, 0]\n",
      " Het is [0.0, 0.0, 1.0], maar je predict[0, 1, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "96.92307692307692"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, score(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien dat de netwerk aardig goede score haa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n1 = Neuron(weights=random_number(4), bias=random_number())\n",
    "# n2 = Neuron(weights=random_number(4), bias=random_number())\n",
    "# n3 = Neuron(weights=random_number(4), bias=random_number())\n",
    "# layer1 = Neuron_layer(neurons = [n1, n2, n3])\n",
    "\n",
    "# n4 = Neuron(weights=random_number(3), bias=random_number())\n",
    "# n5 = Neuron(weights=random_number(3), bias=random_number())\n",
    "# n6 = Neuron(weights=random_number(3), bias=random_number())\n",
    "# layer2 = Neuron_layer(neurons = [n4, n5, n6])\n",
    "\n",
    "# netwerk = Neuron_network(layers=[layer1, layer2])\n",
    "\n",
    "# n1 = Neuron(weights=[random.random(), random.random(), random.random(), random.random()], bias= 0)\n",
    "# n2 = Neuron(weights=[random.random(), random.random(), random.random(), random.random()], bias= 0)\n",
    "# n3 = Neuron(weights=[random.random(), random.random(), random.random(), random.random()], bias= 0)\n",
    "# layer1 = Neuron_layer(neurons = [n1, n2, n3])\n",
    "\n",
    "# n4 = Neuron(weights=[random.random(), random.random(), random.random()], bias=random_number())\n",
    "# n5 = Neuron(weights=[random.random(), random.random(), random.random()], bias=random_number())\n",
    "# n6 = Neuron(weights=[random.random(), random.random(), random.random()], bias=random_number())\n",
    "# layer2 = Neuron_layer(neurons = [n4, n5, n6])\n",
    "\n",
    "# netwerk = Neuron_network(layers=[layer1, layer2])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
